{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32523fe2",
   "metadata": {},
   "source": [
    "# Participant Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56783432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Select whether Angle or Power shall be loaded. \n",
    "# For the participant split, angle with eyes closed was chosen.\n",
    "angle = True\n",
    "closed = True\n",
    "domain = \"_A_\" if angle else \"_P_\" \n",
    "condition = \"_closed\" if closed else \"_open\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0271bec",
   "metadata": {},
   "source": [
    "# Participant Split\n",
    "\n",
    "Note: the participant split varies from run to run, even though I have set a seed. The current split provides a test and train set with a quite equal balance of CC and DC participants; Running this cell will generate a new split, which might not yield  the same results! For safety reasons, I have chosen a different target folder for the splits, than where the currently used splits reside. The split generated here is written to the \"Max\" folder, while the splits used for P8 and 32 channel classification are in the respective folders (same split files in both folders)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562fc0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 6880/6880 [00:00<00:00, 583779.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Participant split according to 60:40\n",
    "\n",
    "os.chdir(\"/home/bpn/Documents/Max/NPZ_200_150/\")\n",
    "\n",
    "# Filter by domain and condition\n",
    "files = [file for file in os.listdir() if domain in file and condition in file]\n",
    "\n",
    "# Read IDs from valid timepoints\n",
    "id_list = []\n",
    "\n",
    "# Iterate over NPZ files to extract all occuring participant IDs\n",
    "for file in tqdm(files):\n",
    "    try:\n",
    "        #Extract ID from name and append it to list\n",
    "        id_ = re.search('TVD_\\d{4}', file)[0]\n",
    "        id_list.append(id_)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "            \n",
    "\n",
    "# Split unique IDs by random permutation\n",
    "id_set = list(set(id_list)) # Deduplicate list by converting it to a set\n",
    "permutation = np.random.RandomState(seed = 270597).permutation(len(id_set)) # Random permutation of unique IDs with fixed seed\n",
    "train_ids = [id_set[ind] for ind in permutation[:round(0.6*len(id_set))]] # Select 60% for Training\n",
    "test_ids = [id_set[ind] for ind in permutation[round(0.6*len(id_set)):]] #Select the rest (40%) for Testing\n",
    "\n",
    "\n",
    "# Save train/test IDs\n",
    "os.chdir(\"/home/bpn/Documents/Max\")\n",
    "\n",
    "with open('train_ids', 'wb') as fp:\n",
    "    pickle.dump(train_ids, fp)\n",
    "\n",
    "with open('test_ids', 'wb') as fp:\n",
    "    pickle.dump(test_ids, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c020c21",
   "metadata": {},
   "source": [
    "# Check number of participants per group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31c2b197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of CCs in trainset: 8\n",
      "No. of DCs in trainset: 12\n",
      "No. of CCs in testset: 5\n",
      "No. of DCs in testset: 7\n"
     ]
    }
   ],
   "source": [
    "# I read the split files from the P8 folder, to which I copied them. \n",
    "# This is done for safety reasons, in case someone runs the cell above by mistake and generates new splits\n",
    "os.chdir(\"/home/bpn/Documents/Max/P8_final\")\n",
    "\n",
    "# Load IDs for Train-Test split \n",
    "with open('train_ids', 'rb') as fp:\n",
    "    train_ids = pickle.load(fp)\n",
    "    \n",
    "with open('test_ids', 'rb') as fp:\n",
    "    test_ids = pickle.load(fp)\n",
    "\n",
    "# Define DC and CC lists\n",
    "dc_list = []\n",
    "for i in (\"206\",\"200\",\"181\",\"177\",\"148\",\"144\",\"136\",\"135\", \"127\",\"112\",\"104\",\"205\",\"010\",\"156\",\"059\",\"606\",\"620\",\"622\",\"624\",\"627\"):\n",
    "    dc_list.append(\"TVD_0\" + i)\n",
    "    \n",
    "cc_list = []\n",
    "for i in (\"001\", \"042\", \"015\", \"277\", \"274\", \"012\", \"050\", \"016\", \"052\", \"070\",\"243\",\"229\",\"050\",\"256\",\"240\", \"145\"):\n",
    "    cc_list.append(\"TVD_0\" + i)\n",
    "\n",
    "print(\"No. of CCs in trainset: %i\"%len([id_ for id_ in train_ids if id_ in cc_list]))\n",
    "print(\"No. of DCs in trainset: %i\"%len([id_ for id_ in train_ids if id_ in dc_list]))\n",
    "print(\"No. of CCs in testset: %i\"%len([id_ for id_ in test_ids if id_ in cc_list]))\n",
    "print(\"No. of DCs in testset: %i\"%len([id_ for id_ in test_ids if id_ in dc_list]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aad4ca",
   "metadata": {},
   "source": [
    "# Extract valid timepoints and split by test- and train-IDs\n",
    "(This needs to be done only once, per domain (Phase and Power) and per condition (closed and open), since the results of this cell are saved as .npy files. If some else takes over this project, the cell below can be skipped, as the files are already in the correct folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2340e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I read the split files from the P8 folder, to which I copied them. \n",
    "# This is done for safety reasons, in case someone runs the cell above by mistake and generates new splits\n",
    "os.chdir(\"/home/bpn/Documents/Max/P8_final\")\n",
    "\n",
    "# Load IDs for Train-Test split \n",
    "with open('train_ids', 'rb') as fp:\n",
    "    train_ids = pickle.load(fp)\n",
    "    \n",
    "with open('test_ids', 'rb') as fp:\n",
    "    test_ids = pickle.load(fp)\n",
    "\n",
    "    \n",
    "os.chdir(\"/home/bpn/Documents/Max/NPZ_200_150\")\n",
    "\n",
    "# Filter by domain and condition\n",
    "files = [file for file in os.listdir() if domain in file and condition in file]\n",
    "\n",
    "# Filter Timepoints\n",
    "timepoints = []\n",
    "for file in files:\n",
    "    timepoints.append(re.search('\\d{3}.\\d{2}', file)[0].split(\".\")[0])\n",
    "\n",
    "# Logic behind valid timepoints: Select only those timepoints that are available for all participants\n",
    "valid_timepoints = set([x for x in set(timepoints) \\\n",
    "                        if (timepoints.count(x) == timepoints.count('002')) \\\n",
    "                        and (x not in['000','001'])]) #Drop seconds 0 and 1 due to artifacts\n",
    "valid_timepoints.remove(max(valid_timepoints)) # Remove latest common timepoint (due to artifacts)\n",
    "valid_timepoints.remove(max(valid_timepoints)) # Remove second latest common timepoint (due to artifacts)\n",
    "\n",
    "\n",
    "# Read in suitable .npz files\n",
    "train_tensors = []\n",
    "train_targets = []\n",
    "test_tensors = []\n",
    "test_targets = []\n",
    "\n",
    "# Iterate over NPZ files in directory\n",
    "for file in tqdm(files):\n",
    "    timepoint = re.search('\\d{3}.\\d{2}', file)[0].split(\".\")[0] # extract timepoint with regex\n",
    "    if timepoint in valid_timepoints: # Only process timepoints that are in the valid list\n",
    "        \n",
    "        try:\n",
    "            #Extract participant ID from filesname with regex\n",
    "            id_ = re.search('TVD_\\d{4}', file)[0]\n",
    "            \n",
    "            #Code target, depending on whether the participant ID is in the CC or DC list\n",
    "            if id_ in cc_list:\n",
    "                target = 1\n",
    "            elif id_ in dc_list:\n",
    "                target = 0\n",
    "            else:\n",
    "                raise ValueError()\n",
    "            \n",
    "            # Load volume, i.e., the NPZ file\n",
    "            vol = iio.volread('%s'%file)\n",
    "            vol = np.transpose(vol, (1,2,0))\n",
    "            \n",
    "            # Append tensors and targets to lists\n",
    "            if id_ in train_ids:\n",
    "                train_tensors.append(vol)\n",
    "                train_targets.append(target)\n",
    "            elif id_ in test_ids:\n",
    "                test_tensors.append(vol)\n",
    "                test_targets.append(target)\n",
    "            else:\n",
    "                raise ValueError()\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    else: \n",
    "        pass\n",
    "\n",
    "######################################\n",
    "# Extract and save 32 channel data ###\n",
    "######################################\n",
    "os.chdir(\"/home/bpn/Documents/Max/32_channels\")\n",
    "\n",
    "np.save(\"Data/32_train%s%s.npy\"%(domain, condition),train_tensors)\n",
    "np.save(\"Data/32_test%s%s.npy\"%(domain, condition),test_tensors)\n",
    "\n",
    "np.save(\"Data/target_train%s%s.npy\"%(domain, condition),train_targets)\n",
    "np.save(\"Data/target_test%s%s.npy\"%(domain, condition),test_targets)\n",
    "\n",
    "\n",
    "##############################\n",
    "# Extract and save P8 data ###\n",
    "##############################\n",
    "os.chdir(\"/home/bpn/Documents/Max/P8_final\")\n",
    "\n",
    "p8_train = []\n",
    "p8_test = []\n",
    "\n",
    "for tensor in train_tensors:\n",
    "    p8_train.append(tensor[:,:,27]) # P8 is the 28th channel, thus 27 as index (Due to 0 indexing in Python)\n",
    "\n",
    "for tensor in test_tensors:\n",
    "    p8_test.append(tensor[:,:,27]) # P8 is the 28th channel, thus 27 as index (Due to 0 indexing in Python)\n",
    "    \n",
    "np.save(\"Data/p8_train%s%s.npy\"%(domain, condition),p8_train)\n",
    "np.save(\"Data/p8_test%s%s.npy\"%(domain, condition),p8_test)\n",
    "\n",
    "np.save(\"Data/target_train%s%s.npy\"%(domain, condition),train_targets)\n",
    "np.save(\"Data/target_test%s%s.npy\"%(domain, condition),test_targets)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
